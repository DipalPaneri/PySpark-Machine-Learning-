{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bd2e465-e277-4333-9848-13acd682958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40946597-8d07-407a-a2ec-d7ce04dde884",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Aggregate').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a515936-b3ab-40ae-82eb-29eb19e3a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"G:\\Downloads Ex\\Python-and-Spark-for-Big-Data-master\\Python-and-Spark-for-Big-Data-master\\Spark_DataFrames\\sales_info.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b6f0a98-e4ee-426e-90df-edb51d122101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Person: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adfb785e-58c1-44a7-9b92-7b1fa94a5423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daa4ae8e-a356-4d4a-b36b-9a304e639cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|Sales|avg(Sales)|\n",
      "+-----+----------+\n",
      "|124.0|     124.0|\n",
      "|350.0|     350.0|\n",
      "|120.0|     120.0|\n",
      "|250.0|     250.0|\n",
      "|340.0|     340.0|\n",
      "|600.0|     600.0|\n",
      "|130.0|     130.0|\n",
      "|243.0|     243.0|\n",
      "|870.0|     870.0|\n",
      "|200.0|     200.0|\n",
      "|750.0|     750.0|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets find out average sale by person\n",
    "df.groupBy('Sales').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc78b540-5e9d-4d72-bfe9-9c98ba1f55b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|Sales|avg(Sales)|\n",
      "+-----+----------+\n",
      "|124.0|     124.0|\n",
      "|350.0|     350.0|\n",
      "|120.0|     120.0|\n",
      "|250.0|     250.0|\n",
      "|340.0|     340.0|\n",
      "|600.0|     600.0|\n",
      "|130.0|     130.0|\n",
      "|243.0|     243.0|\n",
      "|870.0|     870.0|\n",
      "|200.0|     200.0|\n",
      "|750.0|     750.0|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lets find out average sale by company \n",
    "df.groupBy('Sales').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8af4ec86-2aac-4370-80ae-1821c1d7b87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|sum(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|    1480.0|\n",
      "|   GOOG|     660.0|\n",
      "|     FB|    1220.0|\n",
      "|   MSFT|     967.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Summ\n",
    "df.groupby('Company').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59c0b9f5-0a83-4155-90cb-932c76658e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Company|count|\n",
      "+-------+-----+\n",
      "|   APPL|    4|\n",
      "|   GOOG|    3|\n",
      "|     FB|    2|\n",
      "|   MSFT|    3|\n",
      "+-------+-----+\n",
      "\n",
      "+-------+----------+\n",
      "|Company|min(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|     130.0|\n",
      "|   GOOG|     120.0|\n",
      "|     FB|     350.0|\n",
      "|   MSFT|     124.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count of rows or employees in dataframe\n",
    "df.groupby('Company').count().show()\n",
    "#min\n",
    "df.groupby('Company').min().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b94e2372-843b-47cd-81ec-a1d66af32499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(Sales)|\n",
      "+----------+\n",
      "|     870.0|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|sum(Sales)|\n",
      "+----------+\n",
      "|    4327.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's say we want to get all sale total and not the groupBy company, .agg() method which uses dictionary format as an argument\n",
    "df.agg({'Sales':'max'}).show()\n",
    "df.agg({'Sales':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "791e040e-e00a-406d-9db1-84a6b6c2c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = df.groupBy(\"Company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32505ce0-f11e-43c3-bf06-7211823a583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|max(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|     750.0|\n",
      "|   GOOG|     340.0|\n",
      "|     FB|     870.0|\n",
      "|   MSFT|     600.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#we can achieve this on groupBy object as well. \n",
    "group_data.agg({\"Sales\":\"max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "955af2ce-b6ba-4f98-8324-c15c0e60dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count_distinct, avg, stddev, format_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a691b-7f7d-4333-ae46-ace7aa79150f",
   "metadata": {},
   "source": [
    "###Functions\n",
    "There are a variety of functions you can import from pyspark.sql.functions. Check out the documentation for the full list available or hit tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7f28e54-0038-4bf4-bdb9-b3fa63c81da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(sales)|\n",
      "+-----------------+\n",
      "|360.5833333333333|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(avg('sales')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b679a51a-e4cf-48d8-9ead-882a0e022d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|    Total Revenue|\n",
      "+-----------------+\n",
      "|360.5833333333333|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#just like in SQL Queries we can alias the column names as well for better readablility and understanding.\n",
    "df.select(avg(\"sales\").alias(\"Total Revenue\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "657788b8-aa11-406d-b2d9-d082df4f7d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|Standard Deviation|\n",
      "+------------------+\n",
      "|250.08742410799007|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(stddev('sales').alias(\"Standard Deviation\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c69ea-3a91-4318-8d7a-5143534bf99d",
   "metadata": {},
   "source": [
    "There are too many digits for standard deviation. lets Format the numbers t0 2 decimal points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ec59c00-801f-4e13-8066-50483f0beb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_std = df.select(stddev('sales').alias(\"Std\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6602cf0-dbf8-4a35-be45-81b4914f023c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sales_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5671577-85e8-4ad4-86fd-6d7bfb22401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   Std|\n",
      "+------+\n",
      "|250.09|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_std.select(format_number('Std',2).alias(\"Std\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabce637-15f3-47f7-ab48-f1bd7dfb7cd7",
   "metadata": {},
   "source": [
    "###Order By and Sorting Methods used in DataFRame in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97047ee4-cef6-4109-a1f0-1375cee9e341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|     FB|   Carl|870.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"Sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1281e83e-7dc9-4244-85e2-63973efd54e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|     FB|   Carl|870.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#OrderBy in descending order has lil different syntax. \n",
    "df.orderBy(df['Sales'].desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12a889-d831-4b7d-8903-c5f968a6f0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
